# Accurate Body Measurement using R-CNN/PyTorch

A complete Python application for real-time human pose estimation, posture correction, and accurate body measurements using Mask R-CNN and PyTorch.

## üéØ Features

### Real-Time Functionality
- **Live Camera Feed** with real-time pose detection
- **Visual Skeleton Overlay** using R-CNN keypoint detection
- **Color-Coded Feedback**:
  - üî¥ **RED**: Incorrect posture or misalignment
  - üü¢ **GREEN**: Perfect alignment - hold pose
- **Directional Guidance**:
  - "Move back" / "Move closer" (depth/Z-axis)
  - "Move left" / "Move right" (X-axis centering)
  - "Stand up straight" / "Straighten arms"
  - "Move arms away from body"

### Advanced Technical Features
- **R-CNN/Mask R-CNN** implementation using Detectron2
- **PyTorch-based** deep learning backend
- **Training & Testing** infrastructure included
- **Pixel-to-Scale Conversion** using pinhole camera model
- **Camera Calibration** for accurate measurements
- **Auto-Capture** when perfect posture achieved (90 frames / 3 seconds)

### Measurements
Automatically calculates and displays:
- Shoulder Width
- Arm Length (left & right)
- Torso Length
- Hip Width
- Leg Length (left & right)
- Chest Width

### Privacy-First Design
- ‚ö†Ô∏è **NO data storage by default**
- Images saved only temporarily for demonstration
- No video recording
- No keypoint data logging
- Auto-cleanup of temporary files

## üìã Requirements

- Python 3.8+
- CUDA-capable GPU (recommended) or CPU
- Webcam
- Windows/Linux/macOS

## üöÄ Installation

### Step 1: Install PyTorch

Visit [pytorch.org](https://pytorch.org) and install PyTorch for your system.

**Example (CUDA 11.8):**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

**Example (CPU only):**
```bash
pip install torch torchvision
```

### Step 2: Install Detectron2

```bash
# For Linux/macOS
python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

# For Windows (requires Visual Studio Build Tools)
# Follow: https://detectron2.readthedocs.io/en/latest/tutorials/install.html
```

### Step 3: Install Other Dependencies

```bash
pip install -r requirements_rcnn.txt
```

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ main.py              # Main application (real-time capture)
‚îú‚îÄ‚îÄ model_arch.py        # R-CNN model architecture & inference
‚îú‚îÄ‚îÄ pose_utils.py        # Pose alignment & measurement utilities
‚îú‚îÄ‚îÄ dataset.py           # Dataset loading & preprocessing
‚îú‚îÄ‚îÄ train.py             # Training script
‚îú‚îÄ‚îÄ config.py            # Configuration parameters
‚îú‚îÄ‚îÄ requirements_rcnn.txt # Dependencies
‚îî‚îÄ‚îÄ README_RCNN.md       # This file
```

## üéÆ Usage

### Quick Start (Pretrained Model)

Run the application with pretrained COCO weights:

```bash
python main.py
```

### With Custom Height Calibration

For more accurate measurements, provide your height:

```bash
python main.py --height 175
```
(Replace 175 with your height in centimeters)

### Demo Mode (No Camera)

Test with synthetic data:

```bash
python main.py --demo
```

### With Custom Trained Model

```bash
python main.py --weights path/to/your/model.pth
```

## üéì Training Your Own Model

### Step 1: Prepare COCO Dataset

Download COCO 2017 dataset:

```bash
# Create dataset directory
mkdir -p datasets/coco

# Download and extract (Linux/macOS)
cd datasets/coco
wget http://images.cocodataset.org/zips/train2017.zip
wget http://images.cocodataset.org/zips/val2017.zip
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip

unzip train2017.zip
unzip val2017.zip
unzip annotations_trainval2017.zip
```

### Step 2: Train Model

```bash
# Start training
python train.py --mode train

# Resume from checkpoint
python train.py --mode train --resume
```

### Step 3: Evaluate Model

```bash
python train.py --mode eval --checkpoint output/checkpoints/model_final.pth
```

### Step 4: Visualize Training Data

```bash
python train.py --mode visualize --samples 10
```

## ‚öôÔ∏è Configuration

Edit `config.py` to customize:

### Model Parameters
```python
DETECTION_THRESHOLD = 0.7    # Detection confidence threshold
KEYPOINT_THRESHOLD = 0.5     # Keypoint confidence threshold
```

### Alignment Requirements
```python
STABILITY_FRAMES = 30        # Frames to hold pose before capture
ALIGNMENT_THRESHOLD = 0.85   # Minimum alignment score (0-1)
```

### Camera Calibration
```python
FOCAL_LENGTH_MM = 4.0        # Camera focal length
SENSOR_WIDTH_MM = 6.17       # Sensor width
REFERENCE_DISTANCE_CM = 200  # Reference distance for calibration
```

### Privacy Settings
```python
SAVE_IMAGES = False          # Disable image saving (privacy)
AUTO_DELETE_TEMP = True      # Auto-delete temporary files
STORE_RAW_FRAMES = False     # Do not store raw video
STORE_KEYPOINTS = False      # Do not store keypoint data
```

## üéØ Target Pose Requirements

For accurate measurements, the user must:

1. **Face the camera directly** (shoulders horizontal)
2. **Stand up straight** (vertical alignment)
3. **Arms slightly away from body** (minimum 10% of torso width)
4. **Elbows relatively straight** (minimum 160¬∞ angle)
5. **Centered in frame** (within 10% tolerance)
6. **Appropriate distance** (approximately 2 meters)

## üìä How It Works

### 1. Pose Detection (R-CNN)
- Uses Detectron2's Keypoint R-CNN (ResNet-50 FPN backbone)
- Detects 17 COCO keypoints per person
- Runs at ~15-30 FPS on GPU, ~3-5 FPS on CPU

### 2. Alignment Checking
- Compares detected pose to target pose requirements
- Calculates alignment score (0-1) based on:
  - Arm position relative to torso
  - Elbow angles
  - Shoulder/hip symmetry
  - Vertical alignment
- Provides real-time feedback for corrections

### 3. Pixel-to-Scale Conversion
Uses **pinhole camera model**:

```
real_size = (pixel_size √ó distance √ó sensor_width) / (focal_length √ó image_width)
```

Two calibration methods:
- **Reference height**: User provides their height
- **Camera parameters**: Uses focal length and sensor size

### 4. Measurement Calculation
- Calculates Euclidean distances between keypoints
- Converts pixel distances to centimeters using scale factor
- Averages measurements across multiple captures for accuracy

### 5. Auto-Capture
- Monitors alignment for 30 consecutive frames
- Captures 3 high-quality images when perfect pose maintained
- Marks endpoints (shoulders, elbows, wrists, hips) on saved images

## üîß Troubleshooting

### Camera Not Opening
```bash
# Try different camera index
python main.py  # Uses camera 0 by default
```
Edit `config.py` and change `CAMERA_INDEX = 1`

### CUDA Out of Memory
Reduce batch size in `config.py`:
```python
TRAIN_BATCH_SIZE = 2  # Reduce from 4
```

### Slow Performance
- Use GPU instead of CPU
- Reduce frame resolution in `config.py`:
```python
FRAME_WIDTH = 640
FRAME_HEIGHT = 480
```

### Detectron2 Installation Issues (Windows)
**See [INSTALL_WINDOWS.md](INSTALL_WINDOWS.md) for complete Windows installation guide.**

Quick solutions:
1. **Use WSL2** (Recommended - easiest method)
2. Install Visual Studio Build Tools
3. Use pre-built wheel if available
4. Or use MediaPipe version: `python pose_capture.py`

### Alignment Too Sensitive
Adjust tolerances in `config.py`:
```python
POSITION_TOLERANCE = 0.12  # Increase from 0.08
ALIGNMENT_THRESHOLD = 0.75  # Decrease from 0.85
```

## üìù Code Structure

### `main.py`
- Main application loop
- Camera initialization
- Real-time processing
- UI rendering
- Capture management

### `model_arch.py`
- `KeypointRCNN`: Model wrapper for inference
- `ModelTrainer`: Training infrastructure
- `DepthEstimator`: Distance estimation from keypoints
- `CenteringChecker`: Frame centering validation

### `pose_utils.py`
- `PoseUtils`: Geometric calculations (angles, distances)
- `AlignmentChecker`: Pose alignment validation
- `MeasurementCalculator`: Pixel-to-cm conversion
- `SkeletonDrawer`: Visualization utilities

### `dataset.py`
- `COCOKeypointDataset`: COCO dataset loader
- `DataAugmentation`: Training augmentation pipeline
- `SyntheticDataGenerator`: Generate test data
- Dataset registration for Detectron2

### `train.py`
- Training loop
- Evaluation
- Checkpoint management
- Data visualization

### `config.py`
- Centralized configuration
- Model parameters
- Camera settings
- Privacy settings

## üîí Privacy & Security

This application is designed with **privacy-first** principles:

‚úÖ **What we DON'T do:**
- Store raw video frames
- Log keypoint data
- Upload data to servers
- Record video streams
- Save images by default

‚úÖ **What we DO:**
- Process frames in real-time (in memory)
- Auto-delete temporary files
- Save only user-selected images (if enabled)
- Provide clear privacy settings in config

**To enable image saving** (for demonstration):
Edit `config.py`:
```python
SAVE_IMAGES = True
AUTO_DELETE_TEMP = False
```

## üìö Technical Details

### Model Architecture
- **Backbone**: ResNet-50 with Feature Pyramid Network (FPN)
- **Detection Head**: Faster R-CNN
- **Keypoint Head**: Keypoint R-CNN with heatmap prediction
- **Input**: RGB images (any resolution)
- **Output**: 17 keypoints per person (COCO format)

### COCO Keypoint Format
```
0: nose, 1: left_eye, 2: right_eye, 3: left_ear, 4: right_ear,
5: left_shoulder, 6: right_shoulder, 7: left_elbow, 8: right_elbow,
9: left_wrist, 10: right_wrist, 11: left_hip, 12: right_hip,
13: left_knee, 14: right_knee, 15: left_ankle, 16: right_ankle
```

### Performance
- **GPU (RTX 3080)**: ~25 FPS
- **GPU (GTX 1060)**: ~15 FPS
- **CPU (i7-10700K)**: ~3 FPS

## ü§ù Contributing

This is a complete, production-ready implementation. Feel free to:
- Extend with additional measurements
- Improve calibration methods
- Add support for multiple people
- Implement pose comparison features

## üìÑ License

MIT License - Free to use and modify

## üôè Acknowledgments

- **Detectron2**: Facebook AI Research
- **PyTorch**: Meta AI
- **COCO Dataset**: Microsoft COCO Consortium
- **Mask R-CNN**: He et al., 2017

## üìû Support

For issues or questions:
1. Check the Troubleshooting section
2. Review Detectron2 documentation
3. Verify camera and CUDA setup

---

**Built with ‚ù§Ô∏è using PyTorch and Detectron2**
